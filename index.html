<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Reinventing Multi-Agent Collaboration through Gaussian-Image Synergy in Diffusion Policies">
  <meta name="keywords" content="3D Gaussian Reconstruction, Diffusion Policy, 3D Scene Representation, Robot Action Generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Reinventing Multi-Agent Collaboration through Gaussian-Image Synergy in Diffusion Policies</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/icon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Reinventing Multi-Agent Collaboration through Gaussian-Image Synergy in Diffusion Policies</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://ziyeeee.github.io">Ziye Wang</a><sup>1,2&dagger;</sup>,</span>
            <span class="author-block">
              <a href="https://faceong.github.io/">Li Kang</a><sup>3&dagger;</sup>,</span>
            <span class="author-block">
              <a href="https://github.com/IranQin">Yiran Qin</a><sup>1,4&dagger;</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=LX04VqIAAAAJ">Jiahua Ma</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=78fKbCkAAAAJ">Zhanglin Peng</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="http://leibai.site/">Lei Bai</a><sup>5</sup>,</span>
            <span class="author-block">
              <a href="http://www.zhangruimao.site">Ruimao Zhang</a><sup>1&Dagger;</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1&#160;</sup>Sun Yat-sen University</span>,
            <span class="author-block"><sup>2&#160;</sup>The University of Hong Kong</span>,
            <span class="author-block"><sup>3&#160;</sup>Shanghai Jiao Tong University</span>,
            <span class="author-block"><sup>4&#160;</sup>The Chinese University of Hong Kong, Shenzhen</span>,
            <span class="author-block"><sup>5&#160;</sup>Shanghai AI Laboratory</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="conference-block">NeurIPS 2025</span>
          </div>

          <div class="is-size-8 publication-authors">
            <span class="author-block"><sup>&dagger;&#160;</sup>Equal contribution</span>
            <span class="author-block"><sup>&Dagger;&#160;</sup>Corresponding Author</span>
          </div>


          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- pic-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Motivation</h2>
      </div>
      <img src="static\images\motivation.svg"  alt="MY ALT TEXT"/>
        <div class="content has-text-justified">
          <p>
          Both local and global context are essential in multi-agent collaboration. Comparison of
multi-agent decision-making using different types of contextual information. (a) Using only local
context leads to miscoordination such as collisions due to lack of global awareness. (b) Using only
global context provides a holistic scene view but lacks detailed local features, resulting in inaccurate
control, such as biased localization. (c) Our proposed method, GauDP, fuses global context, which
is reconstructed from 2D local images via a shared 3D Gaussian representation, on top of local
observations. This integration enables both accurate localization and coordinated execution. Our
proposed method, based solely on 2D observations, effectively aggregates global context on top of
the local context.
          </p>
        </div>
    </div>
  </div>
</section>

<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Real World Demos</h2>
      </div>
      <div class="columns is-multiline is-centered">
        <div class="column is-4">
          <video poster="" id="tree" autoplay controls muted loop height="100%">
            <source src="static/videos/Card_Box_Stacking.mp4"
            type="video/mp4">
          </video>
          <p class="subtitle is-size-6 has-text-centered">
            Card Box Stacking
          </p>
        </div>
        <div class="column is-4">
          <video poster="" id="tree" autoplay controls muted loop height="100%">
            <source src="static/videos/Card_Box_Handover.mp4"
            type="video/mp4">
          </video>
          <p class="subtitle is-size-6 has-text-centered">
            Card Box Handover
          </p>
        </div>
        <div class="column is-4">
          <video poster="" id="tree" autoplay controls muted loop height="100%">
            <source src="static/videos/Grab_Roller.mp4"
            type="video/mp4">
          </video>
          <p class="subtitle is-size-6 has-text-centered">
            Grab Roller
          </p>
        </div>
      </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recently, effective coordination in embodied multi-agent systems remains a fundamental challengeâ€”particularly 
            in scenarios where agents must balance individual perspectives with global environmental awareness. Existing 
            approaches often struggle to balance fine-grained local control with comprehensive scene understanding, resulting 
            in limited scalability and compromised collaboration quality.
          </p>
          <p>
            In this paper, we present <strong>GauDP</strong>, a novel Gaussian-image synergistic representation that facilitates 
            scalable, perception-aware imitation learning in multi-agent collaborative systems.
            Specifically, <strong>GauDP</strong> constructs a globally consistent 3D Gaussian field from decentralized RGB 
            observations, then dynamically redistributes 3D Gaussian attributes to each agent's local perspective. This enables 
            all agents to adaptively query task-critical features from the shared scene representation while maintaining their 
            individual viewpoints.
            This design facilitates both fine-grained control and globally coherent behavior without requiring additional 
            sensing modalities (e.g., 3D point cloud). 
          </p>
          <p>
            We evaluate <strong>GauDP</strong> on the RoboFactory benchmark, which includes diverse multi-arm manipulation tasks. 
            Our method achieves superior performance over existing image-based methods and approaches the effectiveness of 
            point-cloud-driven methods, while maintaining strong scalability as the number of agents increases.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<!-- Method Overview -->
 <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3"> Method Overview</h2>
      </div>
      <img src="static/images/method2.svg" alt="MY ALT TEXT" style="width:80%; display:block; margin:0 auto;"/>
        <div class="content has-text-justified">
          <p>
<strong>(a)</strong> Overview of the proposed <strong> GauDP </strong> framework for multi-agent imitation learning. Each
agent extracts a local context from its 2D observation. A shared 3D Gaussian field is constructed
from all views to form the global context, which is fused with the local context and passed through
an encoder. The resulting per-agent features are processed by a diffusion policy via cross-attention
to predict actions. <strong>(b)</strong> Pipeline for constructing the global Gaussian field. Multi-view images are
encoded and aggregated via cross-attention, followed by a reconstruction loss Lrec between rendered
and input views to ensure consistency.

          </p>
        </div>
    </div>
  </div>
</section>


<!-- Quantitative Comparison 
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Quantitative Comparison of 3D Gaussian Reconstruction</h2>
      </div>
      <img src="static\images\Reconstruction Results Table.png" alt="MY ALT TEXT"/>
    </div>
  </div>
</section> -->

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3"> Visualization of Reconstruction Results</h2>
      </div>
      <img src="static\images\Reconstruction Results.svg" alt="MY ALT TEXT" style="width:80%; display:block; margin:0 auto;"/>
        <!--<div class="content has-text-justified">
          <p>
            <strong> Visualization of Reconstruction Results. </strong> Our method achieves significantly improved reconstruction quality.

          </p>
        </div> -->
    </div>
  </div>
</section>

<!--Simulation and Real-World Performance -->

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Simulation Performance</h2>
      </div>
      <img src="static/images/simulation result.png" alt="MY ALT TEXT"/>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Real-World Performance</h2>
      </div>
      <img src="static/images/realworld result.png" alt="MY ALT TEXT"/>
    </div>
  </div>
</section>


<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{
    wang2025highdynamic,
    title={High-Dynamic Radar Sequence Prediction for Weather Nowcasting Using Spatiotemporal Coherent Gaussian Representation},
    author={Ziye Wang and Yiran Qin and Lin Zeng and Ruimao Zhang},
    booktitle={The Thirteenth International Conference on Learning Representations},
    year={2025},
    url={https://openreview.net/forum?id=Cjz9Xhm7sI}
}</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            We borrowed the website template from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
            Thanks for the inspiration!
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
